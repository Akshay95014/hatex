{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Problem 2: Getting familiar with TensorFlow\n",
    "\n",
    "*TensorFlow* is one of the most popular deep learning framework developed by Google. If you are new to TensorFlow, please read and play with the sample in [Getting started with TensorFlow](https://www.tensorflow.org/get_started/get_started) to get started.\n",
    "\n",
    "* <b>Learning Objective:</b> In Problem 1, you implemented a fully connected network from scratch on your own. Very tedious to do it all by yourself, right? Well, we actually feel the same thing, that's why we are using tools instead of doing everything from scratch, lonely and depressed. For this part of the assignment, we will familiarize you with a widely-used deep learning framework developed by Google, TensorFlow and walk you through convolutional neural networks and show how to train them.\n",
    "* <b>Provided Codes:</b> We provide the Template class for a simple CNN model as BaseModel, predefined skeletons for conv2d() and max_pool(), as well as the dataset preprocessing parts.\n",
    "* <b>TODOs:</b> You are asked to implement the BaseModel following the detailed instrunctions and design your own model in YourModel to achieve a reasonably good performance for classification task on CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Install and import libraries\n",
    "Install tensorflow and matplotlib.\n",
    "\n",
    "```\n",
    "pip install -U tensorflow matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T02:01:04.948886Z",
     "start_time": "2017-10-13T02:01:04.188024Z"
    },
    "hideCode": true,
    "hidePrompt": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version 1.3.0\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "# Add whatever you want\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print \"TensorFlow Version {}\".format(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T02:01:05.185016Z",
     "start_time": "2017-10-13T02:01:04.950228Z"
    },
    "hideCode": true,
    "hidePrompt": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMcb47f8BRy6cguMhtC8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd8d21df310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test matplotlib\n",
    "x = np.linspace(-3, 3, 100)\n",
    "\n",
    "plt.plot(x, np.maximum(0, x), label='relu')\n",
    "plt.plot(x, 1/(1 + np.exp(-x)), label='sigmoid')\n",
    "plt.plot(x, (1 - np.exp(-2 * x))/(1 + np.exp(-2 * x)), label='tanh')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.title(\"Activation functions\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T02:01:05.218609Z",
     "start_time": "2017-10-13T02:01:05.186328Z"
    },
    "hideCode": true,
    "hidePrompt": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.3.0\n",
      "2.000000 * 3.000000 = 6.000000\n"
     ]
    }
   ],
   "source": [
    "# Test tensorflow\n",
    "print('TensorFlow version: ' + tf.__version__)\n",
    "a = tf.constant(2.0)\n",
    "b = tf.constant(3.0)\n",
    "c = a * b\n",
    "\n",
    "sess = tf.Session()\n",
    "result = sess.run([a, b, c])\n",
    "print('%f * %f = %f' % (result[0], result[1], result[2]))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Load datasets\n",
    "Download [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz) and load the dataset. In this assignment, we will use all 50,000 images for training and 10,000 images for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T02:01:05.416049Z",
     "start_time": "2017-10-13T02:01:05.220001Z"
    },
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "num_training = 49000\n",
    "num_validation = 50000 - num_training\n",
    "num_test = 10000\n",
    "\n",
    "def unpickle(file):\n",
    "    import sys\n",
    "    if sys.version_info.major == 2:\n",
    "        import cPickle\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = cPickle.load(fo)\n",
    "        return dict['data'], dict['labels']\n",
    "    else:\n",
    "        import pickle\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict[b'data'], dict[b'labels']\n",
    "\n",
    "def load_train_data():\n",
    "    \n",
    "\n",
    "    #############################################################################\n",
    "    # TODO: Load training data from cifar-10 dataset                            #\n",
    "    # Load five files from 'data_batch_1' to 'data_batch_5'                     #\n",
    "    # Reshape images and labels to the shape of [50000, 32, 32, 3]              # \n",
    "    # and [50000], respectively                                                 #\n",
    "    #############################################################################\n",
    "    data = []\n",
    "    labels = []\n",
    "    for i in range(1, 6):\n",
    "        batch_data, batch_labels = unpickle('cifar-10-batches-py/data_batch_{}'.format(i))\n",
    "        data.append(batch_data)\n",
    "        labels.append(batch_labels)\n",
    "    data = np.array(data).reshape((50000,32,32,3))\n",
    "    labels = np.array(labels).reshape((50000,))\n",
    "    X_train = data[:49000,]\n",
    "    X_val = data[49000:,]\n",
    "    Y_train = labels[:49000,]\n",
    "    Y_val = labels[49000:,]\n",
    "    return (X_train, Y_train, X_val, Y_val)\n",
    "    \n",
    "    \n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "\n",
    "def load_test_data():\n",
    "    pass\n",
    "    #############################################################################\n",
    "    # TODO: Load testing data from cifar-10 dataset                             #\n",
    "    # Load 'test_batch' file                                                    #\n",
    "    # Reshape images and labels to the shape of [10000, 32, 32, 3]              #\n",
    "    # and [10000], respectively                                                 #\n",
    "    #############################################################################\n",
    "    test_data, test_labels = unpickle('cifar-10-batches-py/test_batch')\n",
    "    return np.array(test_data).reshape(10000,32,32,3), np.array(test_labels).reshape(10000,)\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "\n",
    "# Load cifar-10 data\n",
    "X_train, Y_train, X_val, Y_val = load_train_data()\n",
    "X_test, Y_test = load_test_data()\n",
    "\n",
    "# Check the shape of the dataset\n",
    "assert X_train.shape == (num_training, 32, 32, 3)\n",
    "assert Y_train.shape == (num_training, )\n",
    "assert X_val.shape == (num_validation, 32, 32, 3)\n",
    "assert Y_val.shape == (num_validation, )\n",
    "assert X_test.shape == (num_test, 32, 32, 3)\n",
    "assert Y_test.shape == (10000, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Question 2-1\n",
    "\n",
    "Using the code provided, implement a neural network architecture with an optimization routine according to the specification provided below.\n",
    "\n",
    "**Model:**\n",
    "- Input image with the size 32x32x3\n",
    "- 7x7 convolutional layer with 32 filters, stride of 1, and padding 'SAME'\n",
    "- ReLU activation layer\n",
    "- 3x3 max pooling layer with a stride of 2\n",
    "- 5x5 convolutional layer with 64 filters, stride of 1, and padding 'SAME'\n",
    "- ReLU activation layer\n",
    "- 3x3 max pooling layer with a stride of 2\n",
    "- Flatten layer (8x8x64 -> 4096)\n",
    "- Fully-connected layer with 384 output units (4096 -> 384)\n",
    "- ReLU activation layer\n",
    "- Fully-connected layer with 10 output units (384 -> 10)\n",
    "- Output logits (10)\n",
    "\n",
    "**Optimizer:**\n",
    "- Adam optimizer\n",
    "\n",
    "**Learning rate:**\n",
    "- Set start learning rate as 5e-4 and apply exponential decay every 500 steps with a base of 0.96\n",
    "- Use 'tf.train.exponential_decay' and 'tf.train.AdamOptimizer'\n",
    "\n",
    "**Loss:**\n",
    "- Softmax cross entropy loss\n",
    "- Use 'tf.nn.softmax_cross_entropy_with_logits'\n",
    "\n",
    "\n",
    "Your model **should** achieve about 60% accuracy on validation set in 5 epochs using provided evaluation code.\n",
    "\n",
    "You can modify the template code as you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Define your layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T02:01:05.445609Z",
     "start_time": "2017-10-13T02:01:05.417474Z"
    },
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Define max pooling and conv layers\n",
    "def conv2d(inputs, kernel_size, stride, num_filter):\n",
    "    stride_shape = [1, stride, stride, 1]\n",
    "    filter_shape = [kernel_size, kernel_size, inputs.get_shape()[3], num_filter]\n",
    "\n",
    "    W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "    b = tf.get_variable('b', [1, 1, 1, num_filter], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.nn.conv2d(inputs, W, stride_shape, padding='SAME') + b\n",
    "\n",
    "def max_pool(inputs, kernel_size, stride):\n",
    "    ksize = [1, kernel_size, kernel_size, 1]\n",
    "    strides = [1, stride, stride, 1]\n",
    "    return tf.nn.max_pool(inputs, ksize=ksize, strides=strides, padding='SAME')\n",
    "\n",
    "#############################################################################\n",
    "# TODO: You can add any layers (fully-connected, normalization)             #\n",
    "#############################################################################\n",
    "def fc(inputs, num_outputs):\n",
    "    \n",
    "    return tf.contrib.layers.fully_connected(inputs,\n",
    "                                             num_outputs,\n",
    "                                             )\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Sample convolutional nueral network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T02:09:46.528161Z",
     "start_time": "2017-10-13T02:09:46.275192Z"
    },
    "hideCode": false,
    "hidePrompt": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "class BaseModel(object):\n",
    "    def __init__(self):\n",
    "        self.num_epoch = 5\n",
    "        self.batch_size = 128\n",
    "        self.log_step = 50\n",
    "        self._build_model()\n",
    "\n",
    "    def _model(self):\n",
    "        print('-' * 5 + '  Sample model  ' + '-' * 5)\n",
    "\n",
    "        print('intput layer: ' + str(self.X.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('conv1'):\n",
    "            self.conv1 = conv2d(self.X, 7, 1, 32)\n",
    "            self.relu1 = tf.nn.relu(self.conv1)\n",
    "            self.pool1 = max_pool(self.relu1, 3, 2)            \n",
    "            print('conv1 layer: ' + str(self.pool1.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('conv2'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            # 5x5 convolutional layer with 64 filters, stride of 1, and padding 'SAME'\n",
    "            self.conv2 = conv2d(self.pool1, 5, 1, 64)\n",
    "            self.relu2 = tf.nn.relu(self.conv2)\n",
    "            # 3x3 max pooling layer with a stride of 2\n",
    "            self.pool2 = max_pool(self.relu2, 3, 2)                \n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('conv2 layer: ' + str(self.pool2.get_shape()))\n",
    "\n",
    "\n",
    "        #############################################################################\n",
    "        # TODO: Flatten the output tensor from conv2 layer                          #\n",
    "        #############################################################################\n",
    "        self.flat = tf.reshape(self.pool2, [-1, 8 * 8 * 64])\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################      \n",
    "        print('flat layer: ' + str(self.flat.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('fc3'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            # Fully-connected layer with 384 output units (4096 -> 384)\n",
    "            # ReLU activation layer\n",
    "            self.fc3 = fc(self.flat, 384)\n",
    "            self.relu3 = tf.nn.relu(self.fc3)\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('fc3 layer: ' + str(self.relu3.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('fc4'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            # Fully-connected layer with 10 output units (384 -> 10)\n",
    "\n",
    "            self.fc4 = fc(self.relu3, 10)            \n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('fc4 layer: ' + str(self.fc4.get_shape()))\n",
    "        \n",
    "        # Return the last layer\n",
    "        return self.fc4\n",
    "\n",
    "    def _input_ops(self):\n",
    "        # Placeholders\n",
    "        self.X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "        self.Y = tf.placeholder(tf.int64, [None])\n",
    "        \n",
    "        #############################################################################\n",
    "        # TODO: You can add any placeholders                                        #\n",
    "        #############################################################################\n",
    "        self.is_train = None\n",
    "        self.keep_prob = None\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "    def _build_optimizer(self):\n",
    "        # Adam optimizer 'self.train_op' that minimizes 'self.loss_op'\n",
    "        #############################################################################\n",
    "        # TODO: Complete the following functions                                    #\n",
    "        #############################################################################\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        learning_rate = tf.train.exponential_decay(5e-4, \n",
    "                                                   global_step,\n",
    "                                                   500,\n",
    "                                                   0.96, \n",
    "                                                   staircase=True)\n",
    "        self.train_op = tf.train.AdamOptimizer(learning_rate=learning_rate, \n",
    "                                               beta1=0.9, \n",
    "                                               beta2=0.999, \n",
    "                                               epsilon=1e-08, \n",
    "                                               use_locking=False, \n",
    "                                               name='Adam').minimize(self.loss_op, global_step)\n",
    "        \n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "        \n",
    "    def _loss(self, labels, logits):\n",
    "        # Softmax cross entropy loss 'self.loss_op'\n",
    "        #############################################################################\n",
    "        # TODO: Complete the following functions                                    #\n",
    "        #############################################################################\n",
    "        self.loss_op = tf.nn.softmax_cross_entropy_with_logits(labels=labels,  logits=logits)\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "    def _build_model(self):\n",
    "        # Define input variables\n",
    "        self._input_ops()\n",
    "\n",
    "        # Convert Y to one-hot vector\n",
    "        labels = tf.one_hot(self.Y, 10)\n",
    "\n",
    "        # Build a model and get logits\n",
    "        logits = self._model()\n",
    "\n",
    "        # Compute loss\n",
    "        self._loss(labels, logits)\n",
    "        \n",
    "        # Build optimizer\n",
    "        self._build_optimizer()\n",
    "\n",
    "        # Compute accuracy\n",
    "        predict = tf.argmax(logits, 1)\n",
    "        correct = tf.equal(predict, self.Y)\n",
    "        self.accuracy_op = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        \n",
    "    def train(self, sess, X_train, Y_train, X_val, Y_val):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        step = 0\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        print('-' * 5 + '  Start training  ' + '-' * 5)\n",
    "        for epoch in range(self.num_epoch):\n",
    "            print('train for epoch %d' % epoch)\n",
    "            for i in range(num_training // self.batch_size):\n",
    "                X_ = X_train[i * self.batch_size:(i + 1) * self.batch_size][:]\n",
    "                Y_ = Y_train[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "\n",
    "                #############################################################################\n",
    "                # TODO: You can change feed data as you want                                #\n",
    "                #############################################################################\n",
    "                feed_dict = {self.X: X_, self.Y:Y_}                \n",
    "                #############################################################################\n",
    "                #                             END OF YOUR CODE                              #\n",
    "                #############################################################################\n",
    "                fetches = [self.train_op, self.loss_op, self.accuracy_op]\n",
    "\n",
    "                _, loss, accuracy = sess.run(fetches, feed_dict=feed_dict)\n",
    "                losses.append(loss)\n",
    "                accuracies.append(accuracy)\n",
    "\n",
    "                if step % self.log_step == 0:\n",
    "                    print('iteration (%d): loss = %.3f, accuracy = %.3f' %\n",
    "                        (step, loss, accuracy))\n",
    "                step += 1\n",
    "\n",
    "            #############################################################################\n",
    "            # TODO: Plot training curves                                                #\n",
    "            #############################################################################\n",
    "            # Graph 1. X: epoch, Y: training loss\n",
    "            ax = plt.subplot(121)  \n",
    "            n_iter = num_training // self.batch_size\n",
    "            epochs = range(n_samples)\n",
    "            ax.plot(epochs, losses[epoch * n_iter: (epoch+1)*n_iter ])\n",
    "            ax.xlabel('epoch')\n",
    "            ax.ylabel('training loss')\n",
    "            ax.grid(True)\n",
    "\n",
    "            # Graph 2. X: epoch, Y: training accuracy\n",
    "            \n",
    "            ax = plt.subplot(122)              \n",
    "            ax.plot(epochs, accuracy[epoch * n_iter: (epoch+1)*n_iter ])\n",
    "            ax.xlabel('epoch')\n",
    "            ax.ylabel('training loss')\n",
    "            ax.grid(True)\n",
    "            \n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "\n",
    "            # Print validation results\n",
    "            print('validation for epoch %d' % epoch)\n",
    "            val_accuracy = self.evaluate(sess, X_val, Y_val)\n",
    "            print('-  epoch %d: validation accuracy = %.3f' % (epoch, val_accuracy))\n",
    "\n",
    "    def evaluate(self, sess, X_eval, Y_eval):\n",
    "        eval_accuracy = 0.0\n",
    "        eval_iter = 0\n",
    "        for i in range(X_eval.shape[0] // self.batch_size):\n",
    "            X_ = X_eval[i * self.batch_size:(i + 1) * self.batch_size][:]\n",
    "            Y_ = Y_eval[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "                        \n",
    "            #############################################################################\n",
    "            # TODO: You can change feed data as you want                                #\n",
    "            #############################################################################\n",
    "            feed_dict = {self.X: X_, self.Y:Y_}                \n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            accuracy = sess.run(self.accuracy_op, feed_dict=feed_dict)\n",
    "            eval_accuracy += accuracy\n",
    "            eval_iter += 1\n",
    "        return eval_accuracy / eval_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T02:08:58.154307Z",
     "start_time": "2017-10-13T02:08:57.372532Z"
    },
    "hideCode": true,
    "hidePrompt": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----  Sample model  -----\n",
      "intput layer: (?, 32, 32, 3)\n",
      "conv1 layer: (?, 16, 16, 32)\n",
      "conv2 layer: (?, 8, 8, 64)\n",
      "flat layer: (?, 4096)\n",
      "fc3 layer: (?, 384)\n",
      "fc4 layer: (?, 10)\n",
      "-----  Start training  -----\n",
      "train for epoch 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float argument required, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ba16254dba16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/cpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'***** test accuracy: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-a00d8c3cf2ba>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sess, X_train, Y_train, X_val, Y_val)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     print('iteration (%d): loss = %.3f, accuracy = %.3f' %\n\u001b[0;32m--> 165\u001b[0;31m                         (step, loss, accuracy))\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float argument required, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# Clear old computation graphs\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Train our sample model\n",
    "with tf.Session() as sess:\n",
    "    with tf.device('/cpu:0'):\n",
    "        model = BaseModel()\n",
    "        model.train(sess, X_train, Y_train, X_val, Y_val)\n",
    "        accuracy = model.evaluate(sess, X_test, Y_test)\n",
    "        print('***** test accuracy: %.3f' % accuracy)\n",
    "        saver = tf.train.Saver()\n",
    "        model_path = saver.save(sess, \"lib/tf_models/problem2/csci-599_sample.ckpt\")\n",
    "        print(\"Model saved in %s\" % model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Question 2-2\n",
    "\n",
    "Implement your own model. \n",
    "\n",
    "You can modify the template code as you want and you can use GPU for fast training.\n",
    "\n",
    "These are the techniques that you can try:\n",
    "- Data preprocessing\n",
    "- Data augmentation\n",
    "- Dropout\n",
    "- Batch normalization\n",
    "- More convolutional layers\n",
    "- More training epochs\n",
    "- Learning rate decay\n",
    "- Any other models and techniqes\n",
    "\n",
    "Your model should achieve >= 70% accuracy on the test set of CIFAR-10.\n",
    "\n",
    "If the accuracy of the model reaches to 80% on the test set, you will get 5 extra points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T02:01:07.980540Z",
     "start_time": "2017-10-13T02:01:04.268Z"
    },
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "class YourModel(BaseModel):\n",
    "    def __init__(self):\n",
    "        super(YourModel, self).__init__()\n",
    "        self.num_epoch = 10\n",
    "\n",
    "    def _model(self):\n",
    "        print('-' * 5 + '  Your model  ' + '-' * 5)\n",
    "\n",
    "        #############################################################################\n",
    "        # TODO: Implement you own model here                                        #\n",
    "        #############################################################################\n",
    "                \n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "    #############################################################################\n",
    "    # TODO: You can redefine BaseModel's methods                                #\n",
    "    #############################################################################\n",
    "\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T02:01:07.981328Z",
     "start_time": "2017-10-13T02:01:04.271Z"
    },
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Clear old computation graphs\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "#############################################################################\n",
    "# TODO: Preprocessing                                                       #\n",
    "#############################################################################\n",
    "X_train_ = X_train\n",
    "X_val_ = X_val\n",
    "X_test_ = X_test\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################\n",
    "\n",
    "model = YourModel()\n",
    "model.train(sess, X_train_, Y_train, X_val_, Y_val)\n",
    "accuracy = model.evaluate(sess, X_test_, Y_test)\n",
    "print('***** test accuracy: %.3f' % accuracy)\n",
    "\n",
    "# Save your model\n",
    "saver = tf.train.Saver()\n",
    "model_path = saver.save(sess, \"lib/tf_models/problem2/csci-599_mine.ckpt\")\n",
    "print(\"Model saved in %s\" % model_path)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T02:01:07.982053Z",
     "start_time": "2017-10-13T02:01:04.273Z"
    },
    "collapsed": true,
    "hideCode": true,
    "hidePrompt": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Load your model\n",
    "model = YourModel()\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"lib/tf_models/problem2/csci-599_mine.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": true,
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "153px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
